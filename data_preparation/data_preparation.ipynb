{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_preparation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOkDJ7gpF/QkfICO0E7MEe7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayThibs/gpt-stackoverflow-QA/blob/main/data_preparation/data_preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing StackOverflow QA Data\n",
        "\n",
        "This notebook creates a train, validation, and test sets containing a StackOverflow question with its corresponding top answer."
      ],
      "metadata": {
        "id": "rQvRJXJonVlj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecIr2SADnPks",
        "outputId": "eb845449-f6c8-406c-cd11-759eb1d20385"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Dec  9 00:43:51 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P0    30W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installations"
      ],
      "metadata": {
        "id": "gbCKW2p8pZgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xmltodict wget pyunpack patool --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRqyRljCpWOs",
        "outputId": "58956087-ca2f-475d-9e33-1a214ef254ed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |████▎                           | 10 kB 18.5 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 77 kB 2.8 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "z4UqLTh2pizq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import wget\n",
        "from pyunpack import Archive\n",
        "import xmltodict\n",
        "import xml.etree.ElementTree as ET\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "pd.set_option('display.max_colwidth', None)"
      ],
      "metadata": {
        "id": "M1yzwggapjwp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(3407)"
      ],
      "metadata": {
        "id": "DlmLR2iEqD3H"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting the Data"
      ],
      "metadata": {
        "id": "WfCZpfifx7Fu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://archive.org/download/stackexchange/ai.stackexchange.com.7z'\n",
        "wget.download(url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qpIEFuFzqQ2d",
        "outputId": "78c002c6-7c79-443e-91ec-2e7aa2512205"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ai.stackexchange.com.7z'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.isdir('./data'):\n",
        "    os.mkdir('./data')\n",
        "if len(os.listdir('./data') ) == 0:\n",
        "    Archive('ai.stackexchange.com.7z').extractall(\"./data\")"
      ],
      "metadata": {
        "id": "eqnzkRqUyR7J"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree = ET.parse('./data/Posts.xml')\n",
        "tree = tree.getroot()"
      ],
      "metadata": {
        "id": "k9cVtf841WS9"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xmlstr = ET.tostring(tree, encoding='utf8', method='xml').decode()"
      ],
      "metadata": {
        "id": "2Dq5Rz-K0vox"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soDict = xmltodict.parse(xmlstr)"
      ],
      "metadata": {
        "id": "eWYbTshvz_cJ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soDict['posts']['row'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHANJ_oY6vXt",
        "outputId": "b4d0793f-02bd-473e-ff24-d5ddecbbfbba"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('@AcceptedAnswerId', '3'),\n",
              "             ('@AnswerCount', '5'),\n",
              "             ('@Body',\n",
              "              '<p>What does \"backprop\" mean? Is the \"backprop\" term basically the same as \"backpropagation\" or does it have a different meaning?</p>\\n'),\n",
              "             ('@CommentCount', '0'),\n",
              "             ('@ContentLicense', 'CC BY-SA 4.0'),\n",
              "             ('@CreationDate', '2016-08-02T15:39:14.947'),\n",
              "             ('@FavoriteCount', '1'),\n",
              "             ('@Id', '1'),\n",
              "             ('@LastActivityDate', '2021-07-08T10:45:23.250'),\n",
              "             ('@LastEditDate', '2019-11-16T17:56:22.093'),\n",
              "             ('@LastEditorUserId', '2444'),\n",
              "             ('@OwnerUserId', '8'),\n",
              "             ('@PostTypeId', '1'),\n",
              "             ('@Score', '10'),\n",
              "             ('@Tags',\n",
              "              '<neural-networks><backpropagation><terminology><definitions>'),\n",
              "             ('@Title', 'What is \"backprop\"?'),\n",
              "             ('@ViewCount', '625')])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soDict['posts']['row'][2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSflgTTD0M9Z",
        "outputId": "f824c85b-08fa-4960-de96-f88afa48563f"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('@Body',\n",
              "              '<p>\"Backprop\" is the same as \"backpropagation\": it\\'s just a shorter way to say it. It is sometimes abbreviated as \"BP\".</p>\\n'),\n",
              "             ('@CommentCount', '0'),\n",
              "             ('@ContentLicense', 'CC BY-SA 3.0'),\n",
              "             ('@CreationDate', '2016-08-02T15:40:24.820'),\n",
              "             ('@Id', '3'),\n",
              "             ('@LastActivityDate', '2016-08-02T15:40:24.820'),\n",
              "             ('@OwnerUserId', '4'),\n",
              "             ('@ParentId', '1'),\n",
              "             ('@PostTypeId', '2'),\n",
              "             ('@Score', '15')])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soDict['posts']['row'][0:30]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLmU06PiDk5g",
        "outputId": "cb0477a7-72fa-4981-ba38-37db08314282"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[OrderedDict([('@AcceptedAnswerId', '3'),\n",
              "              ('@AnswerCount', '5'),\n",
              "              ('@Body',\n",
              "               '<p>What does \"backprop\" mean? Is the \"backprop\" term basically the same as \"backpropagation\" or does it have a different meaning?</p>\\n'),\n",
              "              ('@CommentCount', '0'),\n",
              "              ('@ContentLicense', 'CC BY-SA 4.0'),\n",
              "              ('@CreationDate', '2016-08-02T15:39:14.947'),\n",
              "              ('@FavoriteCount', '1'),\n",
              "              ('@Id', '1'),\n",
              "              ('@LastActivityDate', '2021-07-08T10:45:23.250'),\n",
              "              ('@LastEditDate', '2019-11-16T17:56:22.093'),\n",
              "              ('@LastEditorUserId', '2444'),\n",
              "              ('@OwnerUserId', '8'),\n",
              "              ('@PostTypeId', '1'),\n",
              "              ('@Score', '10'),\n",
              "              ('@Tags',\n",
              "               '<neural-networks><backpropagation><terminology><definitions>'),\n",
              "              ('@Title', 'What is \"backprop\"?'),\n",
              "              ('@ViewCount', '625')]),\n",
              " OrderedDict([('@AcceptedAnswerId', '9'),\n",
              "              ('@AnswerCount', '3'),\n",
              "              ('@Body',\n",
              "               '<p>Does increasing the noise in data help to improve the learning ability of a network? Does it make any difference or does it depend on the problem being solved? How is it affect the generalization process overall?</p>\\n'),\n",
              "              ('@CommentCount', '0'),\n",
              "              ('@ContentLicense', 'CC BY-SA 4.0'),\n",
              "              ('@CreationDate', '2016-08-02T15:40:20.623'),\n",
              "              ('@FavoriteCount', '2'),\n",
              "              ('@Id', '2'),\n",
              "              ('@LastActivityDate', '2019-02-23T22:36:37.133'),\n",
              "              ('@LastEditDate', '2019-02-23T22:36:19.090'),\n",
              "              ('@LastEditorUserId', '2444'),\n",
              "              ('@OwnerUserId', '8'),\n",
              "              ('@PostTypeId', '1'),\n",
              "              ('@Score', '14'),\n",
              "              ('@Tags',\n",
              "               '<neural-networks><machine-learning><statistical-ai><generalization>'),\n",
              "              ('@Title', 'How does noise affect generalization?'),\n",
              "              ('@ViewCount', '801')]),\n",
              " OrderedDict([('@Body',\n",
              "               '<p>\"Backprop\" is the same as \"backpropagation\": it\\'s just a shorter way to say it. It is sometimes abbreviated as \"BP\".</p>\\n'),\n",
              "              ('@CommentCount', '0'),\n",
              "              ('@ContentLicense', 'CC BY-SA 3.0'),\n",
              "              ('@CreationDate', '2016-08-02T15:40:24.820'),\n",
              "              ('@Id', '3'),\n",
              "              ('@LastActivityDate', '2016-08-02T15:40:24.820'),\n",
              "              ('@OwnerUserId', '4'),\n",
              "              ('@ParentId', '1'),\n",
              "              ('@PostTypeId', '2'),\n",
              "              ('@Score', '15')]),\n",
              " OrderedDict([('@AcceptedAnswerId', '12'),\n",
              "              ('@AnswerCount', '4'),\n",
              "              ('@Body',\n",
              "               \"<p>When you're writing your algorithm, how do you know how many neurons you need per single layer? Are there any methods for finding the optimal number of them, or is it a rule of thumb?</p>\\n\"),\n",
              "              ('@CommentCount', '0'),\n",
              "              ('@ContentLicense', 'CC BY-SA 3.0'),\n",
              "              ('@CreationDate', '2016-08-02T15:41:22.020'),\n",
              "              ('@FavoriteCount', '11'),\n",
              "              ('@Id', '4'),\n",
              "              ('@LastActivityDate', '2021-01-19T23:54:07.813'),\n",
              "              ('@LastEditDate', '2021-01-19T23:54:07.813'),\n",
              "              ('@LastEditorUserId', '2444'),\n",
              "              ('@OwnerUserId', '8'),\n",
              "              ('@PostTypeId', '1'),\n",
              "              ('@Score', '32'),\n",
              "              ('@Tags',\n",
              "               '<neural-networks><hyperparameter-optimization><artificial-neuron><hyper-parameters><layers>'),\n",
              "              ('@Title',\n",
              "               'How to find the optimal number of neurons per layer?'),\n",
              "              ('@ViewCount', '1123')]),\n",
              " OrderedDict([('@AcceptedAnswerId', '20'),\n",
              "              ('@AnswerCount', '2'),\n",
              "              ('@Body',\n",
              "               '<p>Given the following definition of an intelligent agent (taken from a <a href=\"http://en.wikipedia.org/wiki/Philosophy_of_artificial_intelligence#Intelligent_agent_definition\" rel=\"nofollow noreferrer\">Wikipedia article</a>)</p>\\n\\n<blockquote>\\n  <p>If an agent acts so as to maximize the expected value of a performance measure based on past experience and knowledge then it is intelligent</p>\\n</blockquote>\\n\\n<p>and given that we, humans, all make mistakes, which means that we are not maximizing the expected value of a performance measure, then does this imply that humans are not intelligent? </p>\\n'),\n",
              "              ('@CommentCount', '0'),\n",
              "              ('@ContentLicense', 'CC BY-SA 4.0'),\n",
              "              ('@CreationDate', '2016-08-02T15:43:35.460'),\n",
              "              ('@FavoriteCount', '1'),\n",
              "              ('@Id', '6'),\n",
              "              ('@LastActivityDate', '2019-06-15T18:29:55.520'),\n",
              "              ('@LastEditDate', '2019-06-15T18:25:58.513'),\n",
              "              ('@LastEditorUserId', '2444'),\n",
              "              ('@OwnerUserId', '29'),\n",
              "              ('@PostTypeId', '1'),\n",
              "              ('@Score', '7'),\n",
              "              ('@Tags', '<philosophy><definitions><intelligent-agent>'),\n",
              "              ('@Title',\n",
              "               'Are humans intelligent according to the definition of an intelligent agent?'),\n",
              "              ('@ViewCount', '254')]),\n",
              " OrderedDict([('@AnswerCount', '6'),\n",
              "              ('@Body',\n",
              "               '<p>This <a href=\"https://www.independent.co.uk/life-style/gadgets-and-tech/news/stephen-hawking-artificial-intelligence-could-wipe-out-humanity-when-it-gets-too-clever-humans-could-become-ants-being-stepped-a6686496.html\" rel=\"nofollow noreferrer\">quote by Stephen Hawking</a> has been in headlines for quite some time:</p>\\n<blockquote>\\n<p>Artificial Intelligence could wipe out humanity when it gets too clever as humans will be like ants.</p>\\n</blockquote>\\n<p>Why does he say this? To put it simply: what are the possible threats from AI (that Stephen Hawking is worried about)? If we know that AI is so dangerous, why are we still promoting it? Why is it not banned?</p>\\n<p>What are the adverse consequences of the so-called <a href=\"https://en.wikipedia.org/wiki/Technological_singularity\" rel=\"nofollow noreferrer\">Technological Singularity</a>?</p>\\n'),\n",
              "              ('@ClosedDate', '2016-08-04T01:36:40.283'),\n",
              "              ('@CommentCount', '1'),\n",
              "              ('@ContentLicense', 'CC BY-SA 4.0'),\n",
              "              ('@CreationDate', '2016-08-02T15:45:09.070'),\n",
              "              ('@FavoriteCount', '1'),\n",
              "              ('@Id', '7'),\n",
              "              ('@LastActivityDate', '2021-01-20T00:00:31.027'),\n",
              "              ('@LastEditDate', '2021-01-20T00:00:31.027'),\n",
              "              ('@LastEditorUserId', '2444'),\n",
              "              ('@OwnerUserId', '26'),\n",
              "              ('@PostTypeId', '1'),\n",
              "              ('@Score', '10'),\n",
              "              ('@Tags',\n",
              "               '<agi><superintelligence><singularity><ai-safety><ai-takeover>'),\n",
              "              ('@Title',\n",
              "               'Why does Stephen Hawking say \"Artificial Intelligence will kill us all\"?'),\n",
              "              ('@ViewCount', '544')]),\n",
              " OrderedDict([('@Body',\n",
              "               '<p>Noise in the data, to a reasonable amount, may help the network to generalize better. Sometimes, it has the opposite effect. It partly depends on the kind of noise (\"true\" vs. artificial).</p>\\n\\n<p>The <a href=\"ftp://ftp.sas.com/pub/neural/FAQ3.html#A_noise\" rel=\"nofollow noreferrer\">AI FAQ on ANN</a> gives a good overview. Excerpt:</p>\\n\\n<blockquote>\\n  <p>Noise in the actual data is never a good thing, since it limits the accuracy of generalization that can be achieved no matter how extensive the training set is. On the other hand, injecting artificial noise (jitter) into the inputs during training is one of several ways to improve generalization for smooth functions when you have a small training set.</p>\\n</blockquote>\\n\\n<p>In some field, such as computer vision, it\\'s common to increase the size of the training set by copying some samples and adding some noises or other transformation.</p>\\n'),\n",
              "              ('@CommentCount', '0'),\n",
              "              ('@ContentLicense', 'CC BY-SA 4.0'),\n",
              "              ('@CreationDate', '2016-08-02T15:47:02.993'),\n",
              "              ('@Id', '9'),\n",
              "              ('@LastActivityDate', '2019-02-23T22:36:37.133'),\n",
              "              ('@LastEditDate', '2019-02-23T22:36:37.133'),\n",
              "              ('@LastEditorUserId', '2444'),\n",
              "              ('@OwnerUserId', '4'),\n",
              "              ('@ParentId', '2'),\n",
              "              ('@PostTypeId', '2'),\n",
              "              ('@Score', '9')]),\n",
              " OrderedDict([('@AcceptedAnswerId', '32'),\n",
              "              ('@AnswerCount', '6'),\n",
              "              ('@Body',\n",
              "               \"<p>I'm new to A.I. and I'd like to know in simple words, what is the fuzzy logic concept? How does it help, and when is it used?</p>\\n\"),\n",
              "              ('@CommentCount', '0'),\n",
              "              ('@ContentLicense', 'CC BY-SA 3.0'),\n",
              "              ('@CreationDate', '2016-08-02T15:47:56.593'),\n",
              "              ('@FavoriteCount', '19'),\n",
              "              ('@Id', '10'),\n",
              "              ('@LastActivityDate', '2021-03-31T22:24:53.703'),\n",
              "              ('@LastEditDate', '2018-10-18T10:44:33.687'),\n",
              "              ('@LastEditorUserId', '10135'),\n",
              "              ('@OwnerUserId', '8'),\n",
              "              ('@PostTypeId', '1'),\n",
              "              ('@Score', '48'),\n",
              "              ('@Tags', '<deep-neural-networks><terminology><fuzzy-logic>'),\n",
              "              ('@Title', 'What is fuzzy logic?'),\n",
              "              ('@ViewCount', '2302')]),\n",
              " OrderedDict([('@Body',\n",
              "               '<p>We typically think of machine learning models as modeling two different parts of the training data--the underlying generalizable truth (the signal), and the randomness specific to that dataset (the noise).</p>\\n\\n<p>Fitting both of those parts increases training set accuracy, but fitting the signal also increases test set accuracy (and real-world performance) while fitting the noise decreases both. So we use things like regularization and dropout and similar techniques in order to make it harder to fit the noise, and so more likely to fit the signal.</p>\\n\\n<p>Just increasing the amount of noise in the training data is one such approach, but seems unlikely to be as useful. Compare random jitter to adversarial boosting, for example; the first will slowly and indirectly improve robustness whereas the latter will dramatically and directly improve it.</p>\\n'),\n",
              "              ('@CommentCount', '0'),\n",
              "              ('@ContentLicense', 'CC BY-SA 3.0'),\n",
              "              ('@CreationDate', '2016-08-02T15:48:56.970'),\n",
              "              ('@Id', '11'),\n",
              "              ('@LastActivityDate', '2016-08-02T15:48:56.970'),\n",
              "              ('@OwnerUserId', '10'),\n",
              "              ('@ParentId', '2'),\n",
              "              ('@PostTypeId', '2'),\n",
              "              ('@Score', '9')]),\n",
              " OrderedDict([('@Body',\n",
              "               '<p>There is no direct way to find the optimal number of them: people empirically try and see (e.g., using cross-validation). The most common search techniques are random, manual, and grid searches. </p>\\n\\n<p>There exist more advanced techniques such as Gaussian processes, e.g. <em><a href=\"http://arxiv.org/abs/1609.08703\" rel=\"noreferrer\">Optimizing Neural Network Hyperparameters with Gaussian Processes for Dialog Act Classification</a>, IEEE SLT 2016</em>.</p>\\n'),\n",
              "              ('@CommentCount', '0'),\n",
              "              ('@ContentLicense', 'CC BY-SA 3.0'),\n",
              "              ('@CreationDate', '2016-08-02T15:50:27.867'),\n",
              "              ('@Id', '12'),\n",
              "              ('@LastActivityDate', '2016-09-29T00:24:06.177'),\n",
              "              ('@LastEditDate', '2016-09-29T00:24:06.177'),\n",
              "              ('@LastEditorUserId', '4'),\n",
              "              ('@OwnerUserId', '4'),\n",
              "              ('@ParentId', '4'),\n",
              "              ('@PostTypeId', '2'),\n",
              "              ('@Score', '18')]),\n",
              " OrderedDict([('@AcceptedAnswerId', '163'),\n",
              "              ('@AnswerCount', '1'),\n",
              "              ('@Body',\n",
              "               '<p>In particular, an embedded computer (with limited resources) analyzes live video stream from a traffic camera, trying to pick good frames that contain license plate numbers of passing cars. Once a plate is located, the frame is handed over to an OCR library to extract the registration and use it further.</p>\\n\\n<p>In my country two types of license plates are in common use - rectangular (the typical) and square - actually, somewhat rectangular but \"higher than wider\", with the registration split over two rows.</p>\\n\\n<p>(there are some more types, but let us disregard them; they are a small percent and usually belong to vehicles that lie outside our interest.)</p>\\n\\n<p>Due to the limited resources and need for rapid, real-time processing, the maximum size of the network (number of cells and connections) the system can handle is fixed.</p>\\n\\n<p>Would it be better to split this into two smaller networks, each recognizing one type of registration plates, or will the larger single network handle the two types better?</p>\\n'),\n",
              "              ('@CommentCount', '0'),\n",
              "              ('@ContentLicense', 'CC BY-SA 3.0'),\n",
              "              ('@CreationDate', '2016-08-02T15:52:19.413'),\n",
              "              ('@Id', '13'),\n",
              "              ('@LastActivityDate', '2018-04-12T02:30:42.823'),\n",
              "              ('@LastEditDate', '2018-04-12T02:30:42.823'),\n",
              "              ('@LastEditorUserId', '14723'),\n",
              "              ('@OwnerUserId', '38'),\n",
              "              ('@PostTypeId', '1'),\n",
              "              ('@Score', '9'),\n",
              "              ('@Tags', '<neural-networks><image-recognition>'),\n",
              "              ('@Title',\n",
              "               'Can a single neural network handle recognizing two types of objects, or should it be split into two smaller networks?'),\n",
              "              ('@ViewCount', '153')]),\n",
              " OrderedDict([('@AnswerCount', '6'),\n",
              "              ('@Body',\n",
              "               '<p>The <a href=\"https://en.wikipedia.org/wiki/Turing_test\">Turing Test</a> was the first test of artificial intelligence and is now a bit outdated. The <a href=\"https://en.wikipedia.org/wiki/Turing_test#Total_Turing_test\">Total Turing Test</a> aims to be a more modern test which requires a much more sophisticated system. What techniques can we use to identify an artificial intelligence (weak AI) and an <a href=\"https://en.wikipedia.org/wiki/Artificial_general_intelligence\">artificial general intelligence</a> (strong AI)?</p>\\n'),\n",
              "              ('@CommentCount', '2'),\n",
              "              ('@ContentLicense', 'CC BY-SA 3.0'),\n",
              "              ('@CreationDate', '2016-08-02T15:52:50.827'),\n",
              "              ('@FavoriteCount', '8'),\n",
              "              ('@Id', '15'),\n",
              "              ('@LastActivityDate', '2018-04-11T20:16:35.997'),\n",
              "              ('@LastEditDate', '2016-08-04T14:10:10.990'),\n",
              "              ('@LastEditorUserId', '95'),\n",
              "              ('@OwnerUserId', '9'),\n",
              "              ('@PostTypeId', '1'),\n",
              "              ('@Score', '37'),\n",
              "              ('@Tags', '<turing-test><agi><intelligent-agent><weak-ai>'),\n",
              "              ('@Title',\n",
              "               'Is the Turing Test, or any of its variants, a reliable test of artificial intelligence?'),\n",
              "              ('@ViewCount', '3419')]),\n",
              " OrderedDict([('@AcceptedAnswerId', '142'),\n",
              "              ('@AnswerCount', '1'),\n",
              "              ('@Body',\n",
              "               '<p>What is <a href=\"https://en.wikipedia.org/wiki/Early_stopping\" rel=\"nofollow noreferrer\">early stopping</a> in machine learning and, in general, artificial intelligence? What are the advantages of using this method? How does it help exactly?</p>\\n\\n<p>I\\'d be interested in perspectives and links to recent research.</p>\\n'),\n",
              "              ('@CommentCount', '0'),\n",
              "              ('@ContentLicense', 'CC BY-SA 4.0'),\n",
              "              ('@CreationDate', '2016-08-02T15:53:00.447'),\n",
              "              ('@FavoriteCount', '1'),\n",
              "              ('@Id', '16'),\n",
              "              ('@LastActivityDate', '2019-10-11T22:28:23.457'),\n",
              "              ('@LastEditDate', '2019-10-11T22:28:23.457'),\n",
              "              ('@LastEditorUserId', '2444'),\n",
              "              ('@OwnerUserId', '8'),\n",
              "              ('@PostTypeId', '1'),\n",
              "              ('@Score', '8'),\n",
              "              ('@Tags',\n",
              "               '<deep-learning><definitions><overfitting><regularization><early-stopping>'),\n",
              "              ('@Title', 'What is \"early stopping\" in machine learning?'),\n",
              "              ('@ViewCount', '580')]),\n",
              " OrderedDict([('@AcceptedAnswerId', '45'),\n",
              "              ('@AnswerCount', '4'),\n",
              "              ('@Body',\n",
              "               \"<p>I've heard the idea of the technological singularity, what is it and how does it relate to Artificial Intelligence? Is this the theoretical point where Artificial Intelligence machines have progressed to the point where they grow and learn on their own beyond what humans can do and their growth takes off?  How would we know when we reach this point?</p>\\n\"),\n",
              "              ('@CommentCount', '1'),\n",
              "              ('@ContentLicense', 'CC BY-SA 4.0'),\n",
              "              ('@CreationDate', '2016-08-02T15:53:38.273'),\n",
              "              ('@FavoriteCount', '11'),\n",
              "              ('@Id', '17'),\n",
              "              ('@LastActivityDate', '2020-11-17T13:21:19.530'),\n",
              "              ('@LastEditDate', '2019-09-16T16:23:39.853'),\n",
              "              ('@LastEditorUserId', '2444'),\n",
              "              ('@OwnerUserId', '55'),\n",
              "              ('@PostTypeId', '1'),\n",
              "              ('@Score', '38'),\n",
              "              ('@Tags',\n",
              "               '<philosophy><definitions><agi><superintelligence><singularity>'),\n",
              "              ('@Title',\n",
              "               'What is the concept of the technological singularity?'),\n",
              "              ('@ViewCount', '1463')]),\n",
              " OrderedDict([('@Body',\n",
              "               \"<blockquote>\\n  <p>To put it simply in layman terms, what are the possible threats from AI? </p>\\n</blockquote>\\n\\n<p>Currently, there are no threat. </p>\\n\\n<p>The threat comes if humans create a so-called ultraintelligent machine, a machine that can surpass all intellectual activities by any human. This would be the last invention man would need to do, since this machine is better in inventing machines than humans are (since that is an intellectual activity).  However, this could cause the machine to invent machines that can destruct humans, and we can't stop them because they are so much smarter than we are.</p>\\n\\n<p>This is all hypothetical, no one has even a clue of what an ultraintelligent machine looks like. </p>\\n\\n<blockquote>\\n  <p>If we know that AI is so dangerous why are we still promoting it? Why is it not banned?</p>\\n</blockquote>\\n\\n<p>As I said before, the existence of a ultraintelligent machine is hypothetical. Artificial Intelligence has lots of useful applications (more than this answer can contain), and if we develop it, we get even more useful applications. We just have to be careful that the machines won't overtake us. </p>\\n\"),\n",
              "              ('@CommentCount', '0'),\n",
              "              ('@ContentLicense', 'CC BY-SA 3.0'),\n",
              "              ('@CreationDate', '2016-08-02T15:54:26.937'),\n",
              "              ('@Id', '18'),\n",
              "              ('@LastActivityDate', '2016-08-02T15:54:26.937'),\n",
              "              ('@OwnerUserId', '29'),\n",
              "              ('@ParentId', '7'),\n",
              "              ('@PostTypeId', '2'),\n",
              "              ('@Score', '3')]),\n",
              " OrderedDict([('@Body',\n",
              "               '<p>Because he did not yet know how far away current AI is... Working in an media AI lab, I get this question a lot. But really... we are still a long way from this. The robots still do everything we detailledly describe them to do. Instead of seeing the robot as intelligent, I would look to the human programmer for where the creativity really happens.</p>\\n'),\n",
              "              ('@CommentCount', '0'),\n",
              "              ('@ContentLicense', 'CC BY-SA 3.0'),\n",
              "              ('@CreationDate', '2016-08-02T15:54:29.263'),\n",
              "              ('@Id', '19'),\n",
              "              ('@LastActivityDate', '2016-08-02T15:54:29.263'),\n",
              "              ('@OwnerUserId', '52'),\n",
              "              ('@ParentId', '7'),\n",
              "              ('@PostTypeId', '2'),\n",
              "              ('@Score', '4')]),\n",
              " OrderedDict([('@Body',\n",
              "               '<p>It rather depends on how one defines several of the terms used. For example:</p>\\n\\n<ul>\\n<li>Whether the term \"expected\" is interpreted in a formal (i.e.\\nstatistical) sense.  </li>\\n<li>Whether it\\'s assumed that humans have any kind of utilitarian\\n\"performance measure\".</li>\\n</ul>\\n\\n<p>The motivation for this description of \"agent\" arose from a desire to have a quantitative model - it\\'s not clear that such a model is a good fit for human cognition.</p>\\n\\n<p>However, there are alternative definitions of agents, for example the <a href=\"https://en.wikipedia.org/wiki/Belief%E2%80%93desire%E2%80%93intention_software_model\" rel=\"nofollow noreferrer\">BDI model</a>, which are rather more open-ended and hence more obviously applicable to humans.</p>\\n'),\n",
              "              ('@CommentCount', '0'),\n",
              "              ('@ContentLicense', 'CC BY-SA 4.0'),\n",
              "              ('@CreationDate', '2016-08-02T15:54:45.237'),\n",
              "              ('@Id', '20'),\n",
              "              ('@LastActivityDate', '2019-06-15T18:29:55.520'),\n",
              "              ('@LastEditDate', '2019-06-15T18:29:55.520'),\n",
              "              ('@LastEditorUserId', '2444'),\n",
              "              ('@OwnerUserId', '42'),\n",
              "              ('@ParentId', '6'),\n",
              "              ('@PostTypeId', '2'),\n",
              "              ('@Score', '2')]),\n",
              " OrderedDict([('@AnswerCount', '1'),\n",
              "              ('@Body',\n",
              "               \"<p>I'm worrying that my neural network has become too complex. I don't want to end up with half of the neural network doing nothing but just take up space and resources.</p>\\n<p>So, what are the techniques for detecting and preventing overfitting, to avoid such problems?</p>\\n\"),\n",
              "              ('@CommentCount', '0'),\n",
              "              ('@ContentLicense', 'CC BY-SA 4.0'),\n",
              "              ('@CreationDate', '2016-08-02T15:55:15.957'),\n",
              "              ('@Id', '21'),\n",
              "              ('@LastActivityDate', '2021-01-10T01:03:39.270'),\n",
              "              ('@LastEditDate', '2021-01-10T01:01:09.583'),\n",
              "              ('@LastEditorUserId', '2444'),\n",
              "              ('@OwnerUserId', '8'),\n",
              "              ('@PostTypeId', '1'),\n",
              "              ('@Score', '5'),\n",
              "              ('@Tags',\n",
              "               '<reference-request><optimization><deep-neural-networks><overfitting><generalization>'),\n",
              "              ('@Title',\n",
              "               'What are the techniques for detecting and preventing overfitting?'),\n",
              "              ('@ViewCount', '88')]),\n",
              " OrderedDict([('@Body',\n",
              "               '<p>It\\'s not just Hawking, you hear variations on this refrain from a lot of people.  And given that they\\'re mostly very smart, well educated, well informed people (Elon Musk is another, for example), it probably shouldn\\'t be dismissed out of hand.</p>\\n\\n<p>Anyway, the basic idea seems to be this: If we create \"real\" artificial intelligence, at some point, it will be able to improve itself, which improves it\\'s ability to improve itself, which means it can improve it\\'s ability to improve itself even more, and so on... a runaway cascade leading to \"superhuman intelligence\".  That is to say, leading to something that more intelligent than we area.</p>\\n\\n<p>So what happens if there is an entity on this planet which is literally more intelligent than us (humans)? Would it be a threat to us?  Well, it certainly seems reasonable to speculate that it <em>could</em> be so.   OTOH, we have no particular reason, right now, to think that it <em>will</em> be so. </p>\\n\\n<p>So it seems that Hawking, Musk, etc. are just coming down on the more cautious / fearful side of things.  Since we don\\'t <em>know</em> if a superhuman AI will be dangerous or not, and given that it could be unstoppable if it were to become malicious (remember, it\\'s smarter than we are!), it\\'s a reasonable thing to take under consideration.</p>\\n\\n<p>Eliezer Yudkowsky has also written quite a bit on this subject, including come up with the famous \"AI Box\" experiment.  I think anybody interested in this topic should read some of his material.</p>\\n\\n<p><a href=\"http://www.yudkowsky.net/singularity/aibox/\" rel=\"noreferrer\">http://www.yudkowsky.net/singularity/aibox/</a></p>\\n'),\n",
              "              ('@CommentCount', '2'),\n",
              "              ('@ContentLicense', 'CC BY-SA 3.0'),\n",
              "              ('@CreationDate', '2016-08-02T15:56:10.167'),\n",
              "              ('@Id', '22'),\n",
              "              ('@LastActivityDate', '2016-08-02T15:56:10.167'),\n",
              "              ('@OwnerUserId', '33'),\n",
              "              ('@ParentId', '7'),\n",
              "              ('@PostTypeId', '2'),\n",
              "              ('@Score', '5')]),\n",
              " OrderedDict([('@Body',\n",
              "               '<p>As Andrew Ng <a href=\"http://www.theregister.co.uk/2015/03/19/andrew_ng_baidu_ai/\" rel=\"nofollow noreferrer\">said</a>, worrying about such threat from AI is like worrying about of overpopulation on Mars. It is science fiction. </p>\\n\\n<p><a href=\"https://i.stack.imgur.com/m6jnl.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/m6jnl.png\" alt=\"enter image description here\"></a></p>\\n\\n<p>That being said, given the rise of (much weaker) robots and other (semi-)autonomous agents, the fields of the law and ethics are increasingly incorporating them, e.g. see <a href=\"https://en.wikipedia.org/wiki/Roboethics\" rel=\"nofollow noreferrer\">Roboethics</a>.</p>\\n'),\n",
              "              ('@CommentCount', '0'),\n",
              "              ('@ContentLicense', 'CC BY-SA 3.0'),\n",
              "              ('@CreationDate', '2016-08-02T15:57:19.303'),\n",
              "              ('@Id', '23'),\n",
              "              ('@LastActivityDate', '2016-08-02T15:57:19.303'),\n",
              "              ('@OwnerUserId', '4'),\n",
              "              ('@ParentId', '7'),\n",
              "              ('@PostTypeId', '2'),\n",
              "              ('@Score', '4')]),\n",
              " OrderedDict([('@Body',\n",
              "               \"<p>He says this because it can happen. If something becomes smarter than us, why would it continue to serve us? The worst case scenario is that it takes over all manufacturing processes and consumes all matter to convert it into material capable of computation, extending outward infinitely until all matter is consumed.</p>\\n\\n<p>We know that AI is dangerous but it doesn't matter because most people don't believe in it. It goes against every comfort religion has to offer. Man is the end-all-be-all of the universe and if that fact is disputed, people will feel out of place and purposeless.</p>\\n\\n<p>The fact is most people just don't acknowledge it's possible, or that it will happen in our lifetimes, even though many reputable AI experts put the occurrence of the singularity within two decades. If people truly acknowledged that AI that was smarter than them was possible, wouldn't they be living differently? Wouldn't they be looking to do things that they enjoy, knowing that whatever it is they do that they dread will be automated? Wouldn't everyone be calling for a universal basic income?</p>\\n\\n<p>The other reason we don't ban it is because its promise is so great. One researcher could be augmented by 1,000 digital research assistants. All manual labor could be automated. For the first time, technology offers us real freedom to do whatever we please.</p>\\n\\n<p>But even in this best case scenario where it doesn't overtake us, humans still have to adapt and alter their economic system to one where labor isn't necessary. Otherwise, those who aren't technically-trained will starve and revolt.</p>\\n\"),\n",
              "              ('@CommentCount', '2'),\n",
              "              ('@ContentLicense', 'CC BY-SA 3.0'),\n",
              "              ('@CreationDate', '2016-08-02T15:57:48.363'),\n",
              "              ('@Id', '24'),\n",
              "              ('@LastActivityDate', '2016-08-02T16:46:21.237'),\n",
              "              ('@LastEditDate', '2016-08-02T16:46:21.237'),\n",
              "              ('@LastEditorUserId', '56'),\n",
              "              ('@OwnerUserId', '56'),\n",
              "              ('@ParentId', '7'),\n",
              "              ('@PostTypeId', '2'),\n",
              "              ('@Score', '2')]),\n",
              " OrderedDict([('@Body',\n",
              "               '<p>There are a number of long resources to answer this sort of question: consider Stuart Armstrong\\'s book <a href=\"http://rads.stackoverflow.com/amzn/click/B00IB4N4KU\" rel=\"nofollow\">Smarter Than Us</a>, Nick Bostrom\\'s book <a href=\"http://rads.stackoverflow.com/amzn/click/B00LOOCGB2\" rel=\"nofollow\">Superintelligence</a>, which grew out of this <a href=\"http://www.nickbostrom.com/views/superintelligence.pdf\" rel=\"nofollow\">edge.org answer</a>, <a href=\"http://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html\" rel=\"nofollow\">Tim Urban\\'s explanation</a>, or <a href=\"https://aisafety.wordpress.com/\" rel=\"nofollow\">Michael Cohen\\'s explanation</a>.</p>\\n\\n<p>But here\\'s my (somewhat shorter) answer: intelligence is all about decision-making, and we don\\'t have any reason to believe that humans are anywhere near close to being the best possible at decision-making. Once we are able to build an AI AI researcher (that is, a computer that knows how to make computers better at thinking), the economic and military relevance of humans will rapidly disappear as any decision that could be made by a human could be made better by a computer. (Why have human generals instead of robot generals, human engineers instead of robot engineers, and so on.)</p>\\n\\n<p>This isn\\'t necessarily a catastrophe. If the Vulcans showed up tomorrow and brought better decision-making to Earth, we could avoid a lot of misery. The hard part is making sure that what we get are Vulcans who want us around and happy, instead of something that doesn\\'t share our values.</p>\\n'),\n",
              "              ('@CommentCount', '0'),\n",
              "              ('@ContentLicense', 'CC BY-SA 3.0'),\n",
              "              ('@CreationDate', '2016-08-02T15:58:13.970'),\n",
              "              ('@Id', '25'),\n",
              "              ('@LastActivityDate', '2016-08-02T15:58:13.970'),\n",
              "              ('@OwnerUserId', '10'),\n",
              "              ('@ParentId', '7'),\n",
              "              ('@PostTypeId', '2'),\n",
              "              ('@Score', '3')]),\n",
              " OrderedDict([('@AcceptedAnswerId', '189'),\n",
              "              ('@AnswerCount', '4'),\n",
              "              ('@Body',\n",
              "               \"<p>I've seen emotional intelligence defined as the capacity to be aware of, control, and express one's emotions, and to handle interpersonal relationships judiciously and empathetically.  </p>\\n\\n<ol>\\n<li><p>What are some strategies for artificial intelligence to begin to tackle this problem and develop emotional intelligence for computers?  </p></li>\\n<li><p>Are there examples where this is already happening to a degree today?  </p></li>\\n<li><p>Wouldn't a computer that passes a Turing test necessarily express emotional intelligence or it would be seen as an obvious computer?  </p>\\n\\n<p>Perhaps that is why early programs that pass the test represented young people, who presumably have lower emotional intelligence.</p></li>\\n</ol>\\n\"),\n",
              "              ('@CommentCount', '1'),\n",
              "              ('@ContentLicense', 'CC BY-SA 3.0'),\n",
              "              ('@CreationDate', '2016-08-02T15:58:31.413'),\n",
              "              ('@FavoriteCount', '7'),\n",
              "              ('@Id', '26'),\n",
              "              ('@LastActivityDate', '2021-02-01T01:03:23.217'),\n",
              "              ('@LastEditDate', '2020-03-08T03:17:30.877'),\n",
              "              ('@LastEditorUserId', '2444'),\n",
              "              ('@OwnerUserId', '55'),\n",
              "              ('@PostTypeId', '1'),\n",
              "              ('@Score', '23'),\n",
              "              ('@Tags',\n",
              "               '<emotional-intelligence><turing-test><affective-computing>'),\n",
              "              ('@Title', 'How could emotional intelligence be implemented?'),\n",
              "              ('@ViewCount', '1395')]),\n",
              " OrderedDict([('@Body',\n",
              "               '<p>The problem of the Turing Test is that it tests the machines ability to resemble humans. Not necessarily every form of AI has to resemble humans. This makes the Turing Test less reliable. However, it is still useful since it is an actual test. It is also noteworthy that there is a prize for passing or coming closest to passing the Turing Test, the <a href=\"https://en.wikipedia.org/wiki/Loebner_Prize\">Loebner Prize</a>.</p>\\n\\n<p>The intelligent agent definition of intelligence states that an agent is intelligent if it acts so to maximize the expected value of a performance measure based on past experience and knowledge. (paraphrased from <a href=\"http://en.wikipedia.org/wiki/Philosophy_of_artificial_intelligence#Intelligent_agent_definition\">Wikipedia</a>). This definition is used more often and does not depend on the ability to resemble humans. However, it is harder to test this. </p>\\n'),\n",
              "              ('@CommentCount', '0'),\n",
              "              ('@ContentLicense', 'CC BY-SA 3.0'),\n",
              "              ('@CreationDate', '2016-08-02T16:01:59.740'),\n",
              "              ('@Id', '27'),\n",
              "              ('@LastActivityDate', '2016-08-02T16:01:59.740'),\n",
              "              ('@OwnerUserId', '29'),\n",
              "              ('@ParentId', '15'),\n",
              "              ('@PostTypeId', '2'),\n",
              "              ('@Score', '10')]),\n",
              " OrderedDict([('@AcceptedAnswerId', '143'),\n",
              "              ('@AnswerCount', '5'),\n",
              "              ('@Body',\n",
              "               '<p>Since human intelligence presumably is a function of a natural genetic algorithm in nature, is using a genetic algorithm in a computer an example of artificial intelligence? If not, how do they differ? Or perhaps some are and some are not expressing artificial intelligence depending upon the scale of the algorithm and what it evolves into?</p>\\n'),\n",
              "              ('@CommentCount', '0'),\n",
              "              ('@ContentLicense', 'CC BY-SA 4.0'),\n",
              "              ('@CreationDate', '2016-08-02T16:02:44.553'),\n",
              "              ('@FavoriteCount', '1'),\n",
              "              ('@Id', '28'),\n",
              "              ('@LastActivityDate', '2019-06-20T21:03:43.207'),\n",
              "              ('@LastEditDate', '2019-06-20T20:36:38.073'),\n",
              "              ('@LastEditorUserId', '2444'),\n",
              "              ('@OwnerUserId', '55'),\n",
              "              ('@PostTypeId', '1'),\n",
              "              ('@Score', '12'),\n",
              "              ('@Tags', '<philosophy><genetic-algorithms><terminology>'),\n",
              "              ('@Title',\n",
              "               'Is a genetic algorithm an example of artificial intelligence?'),\n",
              "              ('@ViewCount', '6074')]),\n",
              " OrderedDict([('@Body', ''),\n",
              "              ('@CommentCount', '0'),\n",
              "              ('@ContentLicense', 'CC BY-SA 3.0'),\n",
              "              ('@CreationDate', '2016-08-02T16:03:16.133'),\n",
              "              ('@Id', '29'),\n",
              "              ('@LastActivityDate', '2016-08-04T14:45:26.583'),\n",
              "              ('@LastEditDate', '2016-08-04T14:45:26.583'),\n",
              "              ('@LastEditorUserId', '5'),\n",
              "              ('@OwnerUserId', '5'),\n",
              "              ('@PostTypeId', '5'),\n",
              "              ('@Score', '0')]),\n",
              " OrderedDict([('@Body', ''),\n",
              "              ('@CommentCount', '0'),\n",
              "              ('@ContentLicense', 'CC BY-SA 3.0'),\n",
              "              ('@CreationDate', '2016-08-02T16:03:16.133'),\n",
              "              ('@Id', '30'),\n",
              "              ('@LastActivityDate', '2016-08-02T16:03:16.133'),\n",
              "              ('@LastEditDate', '2016-08-02T16:03:16.133'),\n",
              "              ('@LastEditorUserId', '-1'),\n",
              "              ('@OwnerUserId', '-1'),\n",
              "              ('@PostTypeId', '4'),\n",
              "              ('@Score', '0')]),\n",
              " OrderedDict([('@Body',\n",
              "               '<p>It\\'s analogous to analogue versus digital, or the many shades of gray in between black and white: when evaluating the truthiness of a result, in binary boolean it\\'s either true or false (0 or 1), but when utilizing fuzzy logic, it\\'s an estimated probability between 0 and 1 (such as 0.75 being mostly probably true). It\\'s useful for making calculated decisions when all information needed isn\\'t necessarily available.</p>\\n\\n<p><a href=\"https://en.wikipedia.org/wiki/Fuzzy_logic\" rel=\"noreferrer\">Wikipedia has a fantastic page for this</a>.</p>\\n'),\n",
              "              ('@CommentCount', '0'),\n",
              "              ('@ContentLicense', 'CC BY-SA 3.0'),\n",
              "              ('@CreationDate', '2016-08-02T16:04:09.333'),\n",
              "              ('@Id', '31'),\n",
              "              ('@LastActivityDate', '2016-08-02T16:04:09.333'),\n",
              "              ('@OwnerUserId', '62'),\n",
              "              ('@ParentId', '10'),\n",
              "              ('@PostTypeId', '2'),\n",
              "              ('@Score', '9')]),\n",
              " OrderedDict([('@Body',\n",
              "               '<p><em>As complexity rises, precise statements lose meaning and meaningful statements lose precision.</em> ( Lofti Zadeh ).</p>\\n\\n<p>Fuzzy logic deals with reasoning that is approximate rather than fixed and exact. This may make the reasoning more meaningful for a human:</p>\\n\\n<p><a href=\"https://i.stack.imgur.com/xdHPJ.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/xdHPJ.png\" alt=\"Precision and significance - comic\"></a></p>\\n\\n<hr>\\n\\n<p>Fuzzy logic is an extension of Boolean logic by Lotfi Zadeh in 1965 based on the\\nmathematical theory of fuzzy sets, which is a generalization of the classical set theory.\\nBy introducing the notion of <em>degree in the verification</em> of a condition, thus enabling a\\ncondition to be in a state other than true or false, fuzzy logic provides a very valuable\\nflexibility for reasoning, which makes it possible to take into account inaccuracies and\\nuncertainties.</p>\\n\\n<p>One advantage of fuzzy logic in order to formalize human reasoning is that the rules\\nare set in natural language. For example, here are some rules of conduct that a driver\\nfollows, assuming that he does not want to lose his driver’s licence:</p>\\n\\n<p><a href=\"https://i.stack.imgur.com/TM2UE.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/TM2UE.png\" alt=\"Fuzzy logic decision table\"></a></p>\\n\\n<p>Intuitively, it thus seems that the input variables like in this example are approximately\\nappreciated by the brain, such as the degree of verification of a condition in fuzzy\\nlogic.</p>\\n\\n<hr>\\n\\n<p>I\\'ve written a short <a href=\"https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=kz2aIc8AAAAJ&amp;citation_for_view=kz2aIc8AAAAJ:eQOLeE2rZwMC\" rel=\"noreferrer\">introduction to fuzzy logic</a> that goes into a bit more details but should be very accessible.</p>\\n'),\n",
              "              ('@CommentCount', '1'),\n",
              "              ('@ContentLicense', 'CC BY-SA 4.0'),\n",
              "              ('@CreationDate', '2016-08-02T16:04:39.867'),\n",
              "              ('@Id', '32'),\n",
              "              ('@LastActivityDate', '2020-05-26T17:15:36.130'),\n",
              "              ('@LastEditDate', '2020-05-26T17:15:36.130'),\n",
              "              ('@LastEditorUserId', '2255'),\n",
              "              ('@OwnerUserId', '4'),\n",
              "              ('@ParentId', '10'),\n",
              "              ('@PostTypeId', '2'),\n",
              "              ('@Score', '50')]),\n",
              " OrderedDict([('@Body',\n",
              "               '<p>The concept of \"the singularity\" is when machines outsmart the humans. Although Stephen Hawking opinion is that this situation is inevitable, but I think it\\'ll be very difficult to reach that point, because every A.I. algorithm needs to be programmed by humans, therefore it would be always more limited than its creator.</p>\\n\\n<p>We would probably know when that point when humanity will lose control over Artificial Intelligence where super-smart AI would be in competition with humans and maybe creating more sophisticated intelligent beings occurred, but currently, it\\'s more like science fiction (aka <a href=\"https://en.wikipedia.org/wiki/Skynet_(Terminator)\" rel=\"nofollow noreferrer\">Terminator\\'s Skynet</a>).</p>\\n\\n<p>The risk could involve killing people (like self-flying war <em>drones</em> making their own decision), destroying countries or even the whole planet (like A.I. connected to the nuclear weapons (aka <a href=\"https://en.wikipedia.org/wiki/WarGames\" rel=\"nofollow noreferrer\">WarGames</a> movie), but it doesn\\'t prove the point that the machines would be smarter than humans.</p>\\n'),\n",
              "              ('@CommentCount', '3'),\n",
              "              ('@ContentLicense', 'CC BY-SA 3.0'),\n",
              "              ('@CreationDate', '2016-08-02T16:04:57.997'),\n",
              "              ('@Id', '33'),\n",
              "              ('@LastActivityDate', '2018-04-11T16:38:28.877'),\n",
              "              ('@LastEditDate', '2018-04-11T16:38:28.877'),\n",
              "              ('@LastEditorUserId', '14723'),\n",
              "              ('@OwnerUserId', '8'),\n",
              "              ('@ParentId', '17'),\n",
              "              ('@PostTypeId', '2'),\n",
              "              ('@Score', '3')])]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(soDict['posts']['row'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNvT34nT7iWK",
        "outputId": "4ee0c0c7-442a-4a4a-adc5-668ca36c2f30"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21482"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soQADict = {}"
      ],
      "metadata": {
        "id": "pUkZ9nuvFm_l"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counter = 0\n",
        "\n",
        "for i in range(len(soDict['posts']['row'])):\n",
        "    post = soDict['posts']['row'][i]\n",
        "    if post.__contains__('AcceptedAnswerId'):\n",
        "        post_id = counter\n",
        "        counter += 1\n",
        "        AcceptedAnswerId = int(post['@AcceptedAnswerId'])\n",
        "        soQADict[post_id] = {}\n",
        "        soQADict[post_id]['Title'] = post['@Title']\n",
        "        soQADict[post_id]['Question'] = post['@Body']\n",
        "        soQADict[post_id]['QuestionScore'] = post['@Score']\n",
        "        soQADict[post_id]['QuestionCreationDate'] = post['@CreationDate']\n",
        "        soQADict[post_id]['QuestionTags'] = post['@Tags']\n",
        "        soQADict[post_id]['FavoriteCount'] = post['@FavoriteCount']\n",
        "        soQADict[post_id]['ViewCount'] = post['@ViewCount']\n",
        "        soQADict[post_id]['BestAnswer'] = soDict['posts']['row'][AcceptedAnswerId]['@Body']\n",
        "        soQADict[post_id]['AnswerScore'] = soDict['posts']['row'][AcceptedAnswerId]['@Score']\n",
        "        soQADict[post_id]['AnswerCreationDate'] = soDict['posts']['row'][AcceptedAnswerId]['@CreationDate']"
      ],
      "metadata": {
        "id": "5hhT5r3F6SFt"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soQADict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCtqTQ4UFLv5",
        "outputId": "b7e017dd-3b54-447b-e2c1-929db04bed85"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1': {'AnswerCreationDate': '2016-08-02T15:41:22.020',\n",
              "  'AnswerScore': '32',\n",
              "  'BestAnswer': \"<p>When you're writing your algorithm, how do you know how many neurons you need per single layer? Are there any methods for finding the optimal number of them, or is it a rule of thumb?</p>\\n\",\n",
              "  'FavoriteCount': '1',\n",
              "  'Question': '<p>What does \"backprop\" mean? Is the \"backprop\" term basically the same as \"backpropagation\" or does it have a different meaning?</p>\\n',\n",
              "  'QuestionCreationDate': '2016-08-02T15:39:14.947',\n",
              "  'QuestionScore': '10',\n",
              "  'QuestionTags': '<neural-networks><backpropagation><terminology><definitions>',\n",
              "  'Title': 'What is \"backprop\"?',\n",
              "  'ViewCount': '625'},\n",
              " '2': {'AnswerCreationDate': '2016-08-02T15:50:27.867',\n",
              "  'AnswerScore': '18',\n",
              "  'BestAnswer': '<p>There is no direct way to find the optimal number of them: people empirically try and see (e.g., using cross-validation). The most common search techniques are random, manual, and grid searches. </p>\\n\\n<p>There exist more advanced techniques such as Gaussian processes, e.g. <em><a href=\"http://arxiv.org/abs/1609.08703\" rel=\"noreferrer\">Optimizing Neural Network Hyperparameters with Gaussian Processes for Dialog Act Classification</a>, IEEE SLT 2016</em>.</p>\\n',\n",
              "  'FavoriteCount': '2',\n",
              "  'Question': '<p>Does increasing the noise in data help to improve the learning ability of a network? Does it make any difference or does it depend on the problem being solved? How is it affect the generalization process overall?</p>\\n',\n",
              "  'QuestionCreationDate': '2016-08-02T15:40:20.623',\n",
              "  'QuestionScore': '14',\n",
              "  'QuestionTags': '<neural-networks><machine-learning><statistical-ai><generalization>',\n",
              "  'Title': 'How does noise affect generalization?',\n",
              "  'ViewCount': '801'},\n",
              " '4': {'AnswerCreationDate': '2016-08-02T15:53:00.447',\n",
              "  'AnswerScore': '8',\n",
              "  'BestAnswer': '<p>What is <a href=\"https://en.wikipedia.org/wiki/Early_stopping\" rel=\"nofollow noreferrer\">early stopping</a> in machine learning and, in general, artificial intelligence? What are the advantages of using this method? How does it help exactly?</p>\\n\\n<p>I\\'d be interested in perspectives and links to recent research.</p>\\n',\n",
              "  'FavoriteCount': '11',\n",
              "  'Question': \"<p>When you're writing your algorithm, how do you know how many neurons you need per single layer? Are there any methods for finding the optimal number of them, or is it a rule of thumb?</p>\\n\",\n",
              "  'QuestionCreationDate': '2016-08-02T15:41:22.020',\n",
              "  'QuestionScore': '32',\n",
              "  'QuestionTags': '<neural-networks><hyperparameter-optimization><artificial-neuron><hyper-parameters><layers>',\n",
              "  'Title': 'How to find the optimal number of neurons per layer?',\n",
              "  'ViewCount': '1123'},\n",
              " '6': {'AnswerCreationDate': '2016-08-02T15:57:48.363',\n",
              "  'AnswerScore': '2',\n",
              "  'BestAnswer': \"<p>He says this because it can happen. If something becomes smarter than us, why would it continue to serve us? The worst case scenario is that it takes over all manufacturing processes and consumes all matter to convert it into material capable of computation, extending outward infinitely until all matter is consumed.</p>\\n\\n<p>We know that AI is dangerous but it doesn't matter because most people don't believe in it. It goes against every comfort religion has to offer. Man is the end-all-be-all of the universe and if that fact is disputed, people will feel out of place and purposeless.</p>\\n\\n<p>The fact is most people just don't acknowledge it's possible, or that it will happen in our lifetimes, even though many reputable AI experts put the occurrence of the singularity within two decades. If people truly acknowledged that AI that was smarter than them was possible, wouldn't they be living differently? Wouldn't they be looking to do things that they enjoy, knowing that whatever it is they do that they dread will be automated? Wouldn't everyone be calling for a universal basic income?</p>\\n\\n<p>The other reason we don't ban it is because its promise is so great. One researcher could be augmented by 1,000 digital research assistants. All manual labor could be automated. For the first time, technology offers us real freedom to do whatever we please.</p>\\n\\n<p>But even in this best case scenario where it doesn't overtake us, humans still have to adapt and alter their economic system to one where labor isn't necessary. Otherwise, those who aren't technically-trained will starve and revolt.</p>\\n\",\n",
              "  'FavoriteCount': '1',\n",
              "  'Question': '<p>Given the following definition of an intelligent agent (taken from a <a href=\"http://en.wikipedia.org/wiki/Philosophy_of_artificial_intelligence#Intelligent_agent_definition\" rel=\"nofollow noreferrer\">Wikipedia article</a>)</p>\\n\\n<blockquote>\\n  <p>If an agent acts so as to maximize the expected value of a performance measure based on past experience and knowledge then it is intelligent</p>\\n</blockquote>\\n\\n<p>and given that we, humans, all make mistakes, which means that we are not maximizing the expected value of a performance measure, then does this imply that humans are not intelligent? </p>\\n',\n",
              "  'QuestionCreationDate': '2016-08-02T15:43:35.460',\n",
              "  'QuestionScore': '7',\n",
              "  'QuestionTags': '<philosophy><definitions><intelligent-agent>',\n",
              "  'Title': 'Are humans intelligent according to the definition of an intelligent agent?',\n",
              "  'ViewCount': '254'}}"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EcyKkpUHFN4z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}